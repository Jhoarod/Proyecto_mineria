---
title: "Proyecto_AN"
author: "Jhoan Rodriguez"
date: "2025-10-31"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libreria utilizadas

```{r message=FALSE}
library(formattable)
library(dplyr)
library(tidyverse)
library(readr)
library(ggplot2)
library(scales)
library(knitr)
library(kableExtra)
library(cluster)
library(factoextra)
library(caret)
library(randomForest)
library(fastDummies)
library(DescTools)
library(tinytex)
library(gridExtra)
```

## 1. Introducción

• Breve presentación del proyecto.

• Contextualización del problema y su relevancia.

## 2. Justificación

• Importancia del estudio de datos en el problema abordado.

• Valor agregado del análisis realizado.

## 3. Objetivos

• General: Enunciar el objetivo principal del proyecto.

• Específicos: Al menos tres objetivos que detallen las metas técnicas
del análisis.

### 4. Fases del Proceso KDD.

### 4.1 Dominio del problema

• Describir el contexto del fenómeno o situación a analizar.

• Formular preguntas de investigación o hipótesis que orienten la
minería de datos.

• Identificar la relevancia del problema y su impacto en la toma de
decisiones.

### 4.2 Selección de Datos

### Importacion de datos

```{r}
Data <- read.csv(
  "urban_pluvial_flood_risk_dataset.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
```

### Selección de variables relevantes

Para el análisis, se seleccionan variables que reflejan condiciones
físicas, hidrológicas y urbanas del entorno, es decir, aquellas con
relación directa con el riesgo de inundación o con capacidad de
describir la estructura del terreno y la red de drenaje.

```{r}
# Selección de variables relevantes
DataSeleccion <- Data %>%
  select(
    elevation_m,
    drainage_density_km_per_km2,
    storm_drain_proximity_m,
    historical_rainfall_intensity_mm_hr,
    return_period_years,
    land_use,
    soil_group,
    storm_drain_type
  )

```

## Justificación de la selección:

•elevation_m: La altitud define la capacidad de escurrimiento del agua.

•drainage_density_km_per_km2: Representa la eficiencia de drenaje
urbano.

•storm_drain_proximity_m: Influye directamente en la probabilidad de
acumulación de agua.

•historical_rainfall_intensity_mm_hr: Determina la presión pluvial
histórica en la zona.

•return_period_years: Indica la frecuencia esperada de eventos extremos.

•land_use, soil_group, storm_drain_type: Variables categóricas que
afectan la infiltración, escorrentía y drenaje.

### Limpieza de datos y manejo de valores faltante

El siguiente código elimina filas con valores NA y permite verificar
cuántos registros se mantuvieron:

### Eliminación de filas con NA

```{r}
# Eliminación de registros (filas) con más del 30% de valores NA
DataLimpia <- DataSeleccion %>%
  filter(if_all(everything(), ~ !is.na(.)))

# Mostrar cantidad de filas antes y después
nrow(DataSeleccion)
nrow(DataLimpia)

```

## Motivos de eliminación:

•segment_id: Identificador único, no aporta información para el
análisis.

•city_name, admin_ward, catchment_id: Identificadores geográficos que no
reflejan condiciones físicas o hidrológicas.

•latitude, longitude: Variables espaciales que requieren proyección o
normalización especial.

•dem_source, rainfall_source: Describen la procedencia de los datos, no
influyen directamente en los fenómenos analizados.

•risk_labels: Etiqueta de riesgo, reservada solo para validación, no
debe participar en el entrenamiento del modelo.

#### 4.3 Limpieza de Datos

### Errores e inconsistencias

Se revisó la existencia de valores duplicados o inconsistencias
tipográficas en campos categóricos.

```{r}

DataLimpia<- DataLimpia %>%
  distinct()

```

El resultado es que no existen registros duplicados en el dataset.

### Outliers

Los valores atípicos se detectaron mediante el método de boxplot y
z-score, verificando columnas numéricas como elevation_m o
historical_rainfall_intensity.

## Outliers historical_rainfall_intensity_mm_hr

```{r}
# Detección de outliers por Z-score
z_scores <- scale(DataLimpia[, sapply(DataLimpia, is.numeric)])
outliers <- which(abs(z_scores) > 3, arr.ind = TRUE)

# Visualización de posibles outliers
boxplot(DataLimpia$historical_rainfall_intensity_mm_hr, main="Outliers en intensidad de lluvia")

```

## Outliers storm_drain_proximity_m

```{r}
boxplot(DataLimpia$storm_drain_proximity_m,
        main = "Boxplot de Distancia a Drenaje (storm_drain_proximity_m)")

```

se detectaron valores inconsistentes en la variable elevation_m,
particularmente elevaciones negativas, las cuales no son físicamente
válidas. Por ello, se eliminaron los registros correspondientes

```{r}
#  Eliminar elevaciones negativas
DataLimpia <- DataLimpia[DataLimpia$elevation_m >= 0, ]
```

Posteriormente, para evitar la distorsión que generan valores extremos
en la variable historical_rainfall_intensity_mm_hr, se aplicó el método
de Winsorización, ajustando los valores al percentil 1% y 99%.

```{r}

#winsorización en la columna de lluvia histórica en una variable nueva rainfall_winsorizada
DataLimpia$rainfall_winsorizada <- DescTools::Winsorize(
  DataLimpia$historical_rainfall_intensity_mm_hr,
  val = quantile(
    DataLimpia$historical_rainfall_intensity_mm_hr,
    probs = c(0.01, 0.99),
    na.rm = TRUE
  )
)


```

```{r}
#winsorización en la columna de lluvia histórica en una variable nueva  rainfall_winsorizada
DataLimpia$storm_drain_proximity_winsorizada <- DescTools::Winsorize(
  DataLimpia$storm_drain_proximity_m,
  val = quantile(
    DataLimpia$storm_drain_proximity_m,
    probs = c(0.01, 0.99),
    na.rm = TRUE
  )
)
```

### tratemiendo de datos:

• Variables geográficas: (elevation_m, drainage_density_km_per_km2): Se
mantuvieron sin modificaciones (excepto la corrección de elevaciones
negativas), dado que los valores extremos representan fenómenos reales
del relieve.

• Variables hidrológicas: (historical_rainfall_intensity_mm_hr,
return_period_years, storm_drain_proximity_m): Se aplicó winsorización
al 1% y 99% para limitar la influencia de valores extremos y reducir
sesgos sin afectar el tamaño muestral.

### Justificación:

El uso de winsorización permite preservar la estructura y variabilidad
natural de los datos, evitando la pérdida de información que produciría
la eliminación de registros. Esto mejora la robustez del modelo de
clustering, asegurando que las agrupaciones resultantes reflejen
comportamientos reales y no distorsiones por valores atípicos.

#### 4.4 Transformación de Datos.

El proceso de transformación tiene como propósito adecuar los datos para
el modelado, asegurando que todas las variables sean comparables y
relevantes. Se realizaron las siguientes etapas:

### Normalización de variables numéricas

Las variables numéricas presentan escalas diferentes (metros,
milímetros, años). Para evitar que una variable domine sobre otra en el
clustering, se aplica escalado Min-Max entre 0 y 1.

```{r }

DataTransform <- DataLimpia %>%
  mutate(across(c(elevation_m,
                  drainage_density_km_per_km2,
                  storm_drain_proximity_m,
                  historical_rainfall_intensity_mm_hr,
                  return_period_years),
                ~ (.-min(.)) / (max(.)-min(.)),
                .names = "norm_{col}"))

```

Esto genera nuevas columnas como: norm_elevation_m,
norm_drainage_density_km_per_km2, etc.

### Codificación de variables categóricas

Las variables categóricas land_use, soil_group y storm_drain_type se
transforman a variables numéricas mediante one-hot encoding, técnica
válida y común en minería de datos porque no impone orden artificial
entre categorías.

```{r }

DataTransform <- fastDummies::dummy_cols(DataTransform,
                                         select_columns = c("land_use", "soil_group", "storm_drain_type"),
                                         remove_first_dummy = TRUE,
                                         remove_selected_columns = TRUE)

```

## Justificación:

Se generan columnas binarias como land_use_urban, soil_group_C,
storm_drain_type_open.

### Creación de variables derivadas.

Se crean nuevas variables relevantes para el análisis de riesgo de
inundación y agrupamiento de zonas:

```{r }

DataTransform <- DataTransform %>%
  mutate(
    elevation_rain_ratio = norm_elevation_m / (norm_historical_rainfall_intensity_mm_hr + 0.001),
    drainage_rain_index = norm_drainage_density_km_per_km2 * norm_historical_rainfall_intensity_mm_hr,
    proximity_index = 1 / (norm_storm_drain_proximity_m + 0.01)
  )
```

## Justificación:

•elevation_rain_ratio: relación entre altura y lluvia → zonas bajas con
alta lluvia = mayor riesgo.

•drainage_rain_index: mide la capacidad de drenaje ante lluvias
intensas.

•proximity_index: refleja qué tan cercanas están las zonas a sistemas de
drenaje (mayor valor → más cerca).

### Comparación antes y después.

```{r }
head(DataLimpia %>% select(elevation_m, drainage_density_km_per_km2))
head(DataTransform %>% select(norm_elevation_m, norm_drainage_density_km_per_km2, elevation_rain_ratio))

```

------------------------------------------------------------------------

### Clustering (para segmentar zonas por riesgo.

```{r preparacion-datos-clustering}

data_cluster <- DataTransform %>% 
  select(
    norm_elevation_m,
    norm_drainage_density_km_per_km2,
    norm_storm_drain_proximity_m,
    norm_historical_rainfall_intensity_mm_hr,
    norm_return_period_years,
    starts_with("land_use_"),
    starts_with("soil_group_"),
    starts_with("storm_drain_type_")
  )

data_cluster <- data_cluster %>% 
  select(where(~ !any(is.na(.))))

data_scaled <- scale(data_cluster)
```

# MÉTODO 1: K-MEANS

```{r kmeans-validacion}
cat("\n========== K-MEANS CLUSTERING ==========\n")


p1 <- fviz_nbclust(data_scaled, kmeans, method = "wss", k.max = 10) +
  ggtitle("K-Means: Método del Codo (WSS)")

p2 <- fviz_nbclust(data_scaled, kmeans, method = "silhouette", k.max = 10) +
  ggtitle("K-Means: Método de la Silueta")

gridExtra::grid.arrange(p1, p2, ncol = 2)
```

```{r kmeans-modelo}

set.seed(123)
kmeans_model <- kmeans(data_scaled, centers = 3, nstart = 50, iter.max = 100)


sil_kmeans <- silhouette(kmeans_model$cluster, dist(data_scaled))
avg_sil_kmeans <- mean(sil_kmeans[, 3])

cat("K-Means - Clusters:", 3, "\n")
cat("K-Means - Coeficiente de Silueta:", round(avg_sil_kmeans, 3), "\n")
cat("K-Means - BSS/TSS:", round(kmeans_model$betweenss / kmeans_model$totss * 100, 2), "%\n")
```

```{r kmeans-visualizacion}
fviz_cluster(kmeans_model, data = data_scaled,
             geom = "point",
             ellipse.type = "convex",
             palette = "jco",
             main = "K-Means Clustering (k=3)") +
  theme_minimal()
```

Aquí se observa cómo los datos fueron agrupados por el algoritmo de
K-Means en tres conglomerados bien diferenciados. Los polígonos
alrededor de cada grupo representan el espacio ocupado por cada clúster.

Se evidencia una separación clara entre los tres grupos, lo que indica
que las variables seleccionadas (elevación, tipo de suelo, densidad de
drenaje, proximidad a drenajes, entre otras) aportaron información
suficiente para segmentar zonas con características de riesgo similares.

El clúster identificado como riesgo Alto se concentra hacia los valores
negativos de Dim1 y Dim2, mientras que el riesgo Bajo tiende a ubicarse
hacia valores positivos, confirmando diferencias significativas en las
características geográficas e hidrológicas de cada grupo.

La distribución compacta de cada clúster refuerza la consistencia del
modelo y respalda la fiabilidad de la clasificación realizada.

# MÉTODO 2: CLUSTERING JERÁRQUICO

```{r hierarchical-calculo}
cat("\n========== HIERARCHICAL CLUSTERING ==========\n")

# Matriz de distancias
dist_matrix <- dist(data_scaled, method = "euclidean")

# Clustering jerárquico con método Ward
hc_ward <- hclust(dist_matrix, method = "ward.D2")
```

```{r hierarchical-dendrograma}
# Dendrograma
fviz_dend(hc_ward, k = 3, 
          cex = 0.5,
          palette = "jco",
          rect = TRUE,
          main = "Dendrograma - Clustering Jerárquico (Ward)") +
  theme_minimal()
```

```{r hierarchical-validacion}
# Método de la Silueta para Jerárquico
p_hc_sil <- fviz_nbclust(data_scaled, 
                         FUN = function(x, k) list(cluster = cutree(hc_ward, k)),
                         method = "silhouette", 
                         k.max = 10) +
  ggtitle("Jerárquico: Método de la Silueta")
print(p_hc_sil)
```

```{r hierarchical-corte}
# Cortar dendrograma en 3 clusters
hc_clusters <- cutree(hc_ward, k = 3)

# Métricas Jerárquico
sil_hc <- silhouette(hc_clusters, dist_matrix)
avg_sil_hc <- mean(sil_hc[, 3])

cat("Jerárquico - Clusters:", 3, "\n")
cat("Jerárquico - Coeficiente de Silueta:", round(avg_sil_hc, 3), "\n")
```

```{r hierarchical-visualizacion}
# Visualización Jerárquico
fviz_cluster(list(data = data_scaled, cluster = hc_clusters),
             geom = "point",
             ellipse.type = "convex",
             palette = "jco",
             main = "Clustering Jerárquico Ward (k=3)") +
  theme_minimal()
```

El clustering jerárquico permite observar la estructura de agrupación
mediante un dendrograma, mostrando cómo los datos se fusionan
progresivamente en clusters más grandes.

# ASIGNACIÓN DE CLUSTERS Y NIVELES DE RIESGO

```{r asignacion-clusters}
# Verificar que tenemos el mismo número de filas
cat("Filas en data_scaled:", nrow(data_scaled), "\n")
cat("Filas en DataTransform:", nrow(DataTransform), "\n")
cat("Filas en DataLimpia:", nrow(DataLimpia), "\n")

# Asignar clusters a ambos datasets
DataTransform$Cluster <- as.factor(kmeans_model$cluster)
DataLimpia$Cluster <- as.factor(kmeans_model$cluster)

# Verificar la asignación
cat("Clusters asignados correctamente\n")
print(table(DataTransform$Cluster))
```

```{r calcular-estadisticas-cluster}
# Calcular estadísticas por cluster usando las variables normalizadas
cluster_stats <- DataTransform %>%
  group_by(Cluster) %>%
  summarise(
    n = n(),
    elevacion_promedio = mean(norm_elevation_m, na.rm = TRUE),
    lluvia_promedio = mean(norm_historical_rainfall_intensity_mm_hr, na.rm = TRUE),
    proximidad_drenaje_promedio = mean(norm_storm_drain_proximity_m, na.rm = TRUE),
    densidad_drenaje_promedio = mean(norm_drainage_density_km_per_km2, na.rm = TRUE),
    periodo_retorno_promedio = mean(norm_return_period_years, na.rm = TRUE),
    # También las variables derivadas
    elevation_rain_ratio_promedio = mean(elevation_rain_ratio, na.rm = TRUE),
    drainage_rain_index_promedio = mean(drainage_rain_index, na.rm = TRUE),
    proximity_index_promedio = mean(proximity_index, na.rm = TRUE),
    .groups = 'drop'
  )

cat("\n========== ESTADÍSTICAS POR CLUSTER ==========\n")
print(cluster_stats)
```

```{r crear-indice-riesgo}
# Crear índice de riesgo compuesto para cada cluster
cluster_stats <- cluster_stats %>%
  mutate(
    # Índice de riesgo usando variables normalizadas y derivadas
    # Las variables ya están normalizadas (0-1)
    risk_index = (1 - elevacion_promedio) * 0.30 +        # Elevación baja aumenta riesgo
                 lluvia_promedio * 0.25 +                  # Lluvia alta aumenta riesgo
                 proximidad_drenaje_promedio * 0.20 +      # Lejos de drenaje aumenta riesgo
                 (1 - drainage_rain_index_promedio) * 0.15 + # Bajo índice drenaje-lluvia aumenta riesgo
                 (1 - proximity_index_promedio) * 0.10     # Bajo índice proximidad aumenta riesgo
  ) %>%
  arrange(desc(risk_index))

cat("\n========== ÍNDICE DE RIESGO POR CLUSTER ==========\n")
print(cluster_stats %>% select(Cluster, risk_index))
```

```{r asignar-nivel-riesgo}
# Asignar nivel de riesgo según el índice
cluster_stats <- cluster_stats %>%
  mutate(
    risk_level = case_when(
      risk_index >= quantile(risk_index, 0.67) ~ "Alto",
      risk_index >= quantile(risk_index, 0.33) ~ "Medio",
      TRUE ~ "Bajo"
    )
  )

cat("\n========== PERFILES DE RIESGO POR CLUSTER ==========\n")
print(cluster_stats %>% select(Cluster, risk_index, risk_level, 
                               elevacion_promedio, lluvia_promedio, 
                               proximidad_drenaje_promedio,
                               elevation_rain_ratio_promedio))
```

```{r mapear-riesgo-dataset}
# Mapear niveles de riesgo a ambos datasets
risk_mapping <- setNames(cluster_stats$risk_level, cluster_stats$Cluster)
DataTransform$risk_level <- risk_mapping[as.character(DataTransform$Cluster)]
DataLimpia$risk_level <- risk_mapping[as.character(DataLimpia$Cluster)]

# Convertir a factor con niveles ordenados
DataTransform$risk_level <- factor(DataTransform$risk_level, 
                                   levels = c("Bajo", "Medio", "Alto"))
DataLimpia$risk_level <- factor(DataLimpia$risk_level, 
                                levels = c("Bajo", "Medio", "Alto"))

cat("\n========== MAPEO COMPLETADO ==========\n")
cat("Niveles de riesgo asignados a DataTransform y DataLimpia\n")
```

```{r distribucion-final-riesgo}
# Distribución final
cat("\n========== DISTRIBUCIÓN FINAL POR NIVEL DE RIESGO ==========\n")
print(table(DataLimpia$risk_level))
cat("\nPorcentajes:\n")
print(round(prop.table(table(DataLimpia$risk_level)) * 100, 2))
```

# VISUALIZACIONES FINALES

```{r viz-distribucion-riesgo}
# Visualización 1: Distribución de riesgo (Elevación vs Lluvia)
ggplot(DataLimpia, aes(x = elevation_m, y = historical_rainfall_intensity_mm_hr, 
                              color = risk_level)) +
  geom_point(alpha = 0.6, size = 1.5) +
  scale_color_manual(values = c("Bajo" = "#2ecc71", 
                                 "Medio" = "#f39c12", 
                                 "Alto" = "#e74c3c")) +
  labs(title = "Distribución de Riesgo de Inundación por Cluster",
       subtitle = "K-Means con k=3",
       x = "Elevación (m)",
       y = "Intensidad de lluvia histórica (mm/hr)",
       color = "Nivel de Riesgo") +
  theme_minimal() +
  theme(legend.position = "right",
        plot.title = element_text(face = "bold", size = 14))
```

Se evidencia la distribución del riesgo de inundación según los
clústeres obtenidos, con base en dos variables ambientales clave:
elevación (m) y la intensidad histórica de lluvia (mm/hr). Las áreas con
menor elevación y mayor intensidad de lluvia histórica presentan mayor
concentración de puntos correspondientes al clúster de riesgo Alto.

```{r viz-boxplots-comparativos}
# Visualización 2: Boxplots comparativos
DataLimpia %>%
  select(risk_level, elevation_m, historical_rainfall_intensity_mm_hr, 
         drainage_density_km_per_km2, storm_drain_proximity_m) %>%
  pivot_longer(cols = -risk_level, names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = risk_level, y = value, fill = risk_level)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~variable, scales = "free_y", ncol = 2,
             labeller = labeller(variable = c(
               "elevation_m" = "Elevación (m)",
               "historical_rainfall_intensity_mm_hr" = "Intensidad lluvia (mm/hr)",
               "drainage_density_km_per_km2" = "Densidad drenaje (km/km²)",
               "storm_drain_proximity_m" = "Proximidad drenaje (m)"
             ))) +
  scale_fill_manual(values = c("Bajo" = "#2ecc71", 
                                "Medio" = "#f39c12", 
                                "Alto" = "#e74c3c")) +
  labs(title = "Comparación de Variables por Nivel de Riesgo",
       x = "Nivel de Riesgo", 
       y = "Valor") +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 14),
        strip.text = element_text(face = "bold"))
```

Los boxplots muestran la distribución de cada variable clave según el
nivel de riesgo asignado, confirmando la coherencia de la clasificación.

```{r viz-barras-distribucion}
# Visualización 3: Barras de distribución
ggplot(DataLimpia, aes(x = risk_level, fill = risk_level)) +
  geom_bar(alpha = 0.8) +
  geom_text(stat = 'count', aes(label = after_stat(count)), 
            vjust = -0.5, size = 4, fontface = "bold") +
  scale_fill_manual(values = c("Bajo" = "#2ecc71", 
                                "Medio" = "#f39c12", 
                                "Alto" = "#e74c3c")) +
  labs(title = "Distribución de Registros por Nivel de Riesgo",
       x = "Nivel de Riesgo",
       y = "Cantidad de registros") +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 14))
```

```{r estadisticas-finales-riesgo}
# ESTADÍSTICAS FINALES POR NIVEL DE RIESGO
cat("\n========== ESTADÍSTICAS DESCRIPTIVAS POR NIVEL DE RIESGO ==========\n")

# Estadísticas usando datos originales de DataLimpia
stats_finales <- DataLimpia %>%
  group_by(risk_level) %>%
  summarise(
    n = n(),
    porcentaje = round(n() / nrow(DataLimpia) * 100, 2),
    elevacion_media = round(mean(elevation_m, na.rm = TRUE), 2),
    elevacion_sd = round(sd(elevation_m, na.rm = TRUE), 2),
    lluvia_media = round(mean(historical_rainfall_intensity_mm_hr, na.rm = TRUE), 2),
    lluvia_sd = round(sd(historical_rainfall_intensity_mm_hr, na.rm = TRUE), 2),
    proximidad_drenaje_media = round(mean(storm_drain_proximity_m, na.rm = TRUE), 2),
    densidad_drenaje_media = round(mean(drainage_density_km_per_km2, na.rm = TRUE), 2),
    .groups = 'drop'
  )

print(stats_finales)

# Estadísticas usando variables transformadas de DataTransform
cat("\n========== ESTADÍSTICAS CON VARIABLES NORMALIZADAS Y DERIVADAS ==========\n")
stats_transform <- DataTransform %>%
  group_by(risk_level) %>%
  summarise(
    n = n(),
    elevacion_norm_media = round(mean(norm_elevation_m, na.rm = TRUE), 3),
    lluvia_norm_media = round(mean(norm_historical_rainfall_intensity_mm_hr, na.rm = TRUE), 3),
    elevation_rain_ratio_media = round(mean(elevation_rain_ratio, na.rm = TRUE), 3),
    drainage_rain_index_media = round(mean(drainage_rain_index, na.rm = TRUE), 3),
    proximity_index_media = round(mean(proximity_index, na.rm = TRUE), 3),
    .groups = 'drop'
  )

print(stats_transform)

cat("\n========== ANÁLISIS DE CLUSTERING COMPLETADO ==========\n")
cat("Método utilizado: K-Means (k=3)\n")
cat("Coeficiente de Silueta:", round(avg_sil_kmeans, 3), "\n")
cat("Varianza explicada (BSS/TSS):", round(kmeans_model$betweenss / kmeans_model$totss * 100, 2), "%\n")
```

```{r}
library(ggplot2)

ggplot(DataLimpia, aes(x = elevation_m, y = historical_rainfall_intensity_mm_hr, color = risk_level)) +
  geom_point() +
  labs(title = "Distribución de Riesgo de Inundación por Clúster",
       x = "Elevación (m)",
       y = "Intensidad de lluvia histórica (mm/hr)") +
  theme_minimal()
```

```{r estadisticas-finales}
# Estadísticas descriptivas por nivel de riesgo
cat("\n========== ESTADÍSTICAS POR NIVEL DE RIESGO ==========\n")
DataLimpia %>%
  filter(risk_level != "Sin clasificar") %>%
  group_by(risk_level) %>%
  summarise(
    n = n(),
    elevacion_promedio = round(mean(elevation_m, na.rm = TRUE), 2),
    lluvia_promedio = round(mean(historical_rainfall_intensity_mm_hr, na.rm = TRUE), 2),
    proximidad_drenaje = round(mean(storm_drain_proximity_m, na.rm = TRUE), 2),
    .groups = 'drop'
  ) %>%
  print()

cat("\n========== ANÁLISIS DE CLUSTERING COMPLETADO ==========\n")
```

\`\`\`

Se evidencia la distribución del riesgo de inundación según los
clústeres obtenidos, con base en dos variables ambientales clave:
elevación (m) y la intensidad histórica de lluvia (mm/hr). Se observa
que:

Las áreas con menor elevación y mayor intensidad de lluvia histórica
presentan mayor concentración de puntos correspondientes al clúster de
riesgo Alto, indicando mayor susceptibilidad a inundaciones.

El clúster de riesgo Medio se ubica en una zona intermedia tanto en
elevación como en precipitación.

El clúster de riesgo Bajo se encuentra mayormente distribuido en zonas
con elevaciones más altas y menor intensidad de lluvia, lo cual sugiere
condiciones más seguras frente a posibles inundaciones.

## 4.5 Minería de Datos

• Seleccionar y justificar el algoritmo o técnica empleada
(clasificación, regresión, clustering, etc.).

• Describir la división de datos (entrenamiento y prueba).

• Presentar las métricas de evaluación (Accuracy, F1-Score, MAE, etc.).

• Incluir visualizaciones que respalden los resultados del modelo.

## 4.6 Interpretación y Evaluación

• Analizar críticamente los resultados obtenidos.

• Validar el conocimiento descubierto frente a las hipótesis y objetivos
planteados.

• Evaluar el valor del conocimiento extraído para el contexto del
problema.

## 5. Conclusiones

• Sintetizar los principales hallazgos.

• Reflexionar sobre el proceso completo y sus limitaciones.

• Proponer posibles trabajos futuros o mejoras.

## 6. Anexos

• Gráficos, tablas, fragmentos de código, resultados adicionales que
complementen el análisis.
